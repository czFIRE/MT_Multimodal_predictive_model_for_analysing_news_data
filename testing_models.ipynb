{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of the \"classification\" label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, RobertaModel, RobertaTokenizer, ViTModel, BlipProcessor, BlipForQuestionAnswering , CLIPProcessor, CLIPModel, get_linear_schedule_with_warmup, AutoModelForSequenceClassification, AutoModelForImageClassification, AutoImageProcessor\n",
    "from transformers import BeitImageProcessor, BeitForImageClassification\n",
    "import pickle \n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_combined = pd.read_csv('df_combined.csv')\n",
    "df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_save_location(model_path):\n",
    "    parts = model_path.split('/', 1)  # Split at the first \"/\" encountered\n",
    "    return parts[1] if len(parts) > 1 else model_path\n",
    "\n",
    "def get_multimodal_model_save_location(nlp_model_path, image_model_path, operation):\n",
    "    nlp_parts = nlp_model_path.split('/', 1)\n",
    "    nlp_tmp = nlp_parts[1] if len(nlp_parts) > 1 else nlp_model_path\n",
    "    image_parts = image_model_path.split('/', 1)\n",
    "    image_tmp = image_parts[1] if len(image_parts) > 1 else image_model_path\n",
    "    return f\"{nlp_tmp}_{image_tmp}_{operation}\"\n",
    "\n",
    "def save_model_path(model_name):\n",
    "    return f\"./trained_models/{model_name}.pt\"\n",
    "\n",
    "def save_predictions_path(model_name):\n",
    "    return f\"./trained_results/{model_name}.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/BAAI/bge-reranker-large"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts.to_numpy()\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create data loaders\n",
    "def create_data_loader(texts, labels, tokenizer, max_len, batch_size):\n",
    "    ds = ClassifierDataset(\n",
    "        texts=texts,\n",
    "        labels=labels,\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "class NLPClassifier(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained_model_base):\n",
    "        super(NLPClassifier, self).__init__()\n",
    "        self.nlp_model = pretrained_model_base\n",
    "        self.text_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.hidden = nn.Linear(self.nlp_model.config.hidden_size, 128)  # Change 128 to your desired hidden layer size\n",
    "        self.out = nn.Linear(128, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        text_output = self.nlp_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # text_pooled_output = text_output.last_hidden_state[:, 0, :]\n",
    "        text_pooled_output = self.text_pooling(text_output.last_hidden_state.transpose(1, 2)).view(-1, self.nlp_model.config.hidden_size)\n",
    "        \n",
    "        output = self.drop(text_pooled_output)\n",
    "        output = nn.ReLU()(self.hidden(output))\n",
    "        # return self.out(output)\n",
    "        return torch.nn.functional.log_softmax(self.out(output), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal = False\n",
    "\n",
    "# Check if CUDA is available and set PyTorch to use GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "model_path = 'roberta-base'\n",
    "# model_path = 'BAAI/bge-reranker-large'\n",
    "# model_path = 'openbmb/Eurus-RM-7b' - has problems, TODO fix\n",
    "# model_path = 'facebook/bart-large-cnn'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "base_model = AutoModel.from_pretrained(model_path).to(device)\n",
    "\n",
    "data_subset = df_combined#[:50]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(data_subset['classification_by_editorial'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(data_subset['text'], encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "BATCH_SIZE = 200  # maximum for BGE is ~116\n",
    "MAX_LEN = 256\n",
    "\n",
    "train_data_loader = create_data_loader(train_texts, train_labels, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_texts, test_labels, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "# Initialize the classifier and optimizer\n",
    "model = NLPClassifier(len(le.classes_), base_model).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = CrossEntropyLoss().to(device)\n",
    "\n",
    "# Define the number of training epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'STARTING Epoch {epoch + 1}/{EPOCHS}')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_data_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(test_data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = total_loss / len(test_data_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {avg_train_loss}, Test Loss: {avg_test_loss}\")\n",
    "\n",
    "# Plotting the training and testing losses\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Testing loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in tqdm(test_data_loader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Save model:\n",
    "torch.save(model.state_dict(), save_model_path(get_model_save_location(model_path)))\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(le.inverse_transform(true_labels), le.inverse_transform(predictions)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 epochs with Roberta model:\n",
    "\n",
    "```\n",
    "Accuracy: 0.9721559074299635\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.88      0.97      0.92      3908\n",
    "           1       0.99      0.98      0.98     17162\n",
    "           2       0.93      0.87      0.90      2410\n",
    "           3       0.99      0.98      0.98     17570\n",
    "\n",
    "    accuracy                           0.97     41050\n",
    "   macro avg       0.95      0.95      0.95     41050\n",
    "weighted avg       0.97      0.97      0.97     41050\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 epochs with BGE-Reranker large\n",
    "\n",
    "```\n",
    "Accuracy: 0.9645155000974849\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.91      0.93      0.92      3870\n",
    "           1       0.98      0.98      0.98     17201\n",
    "           2       0.82      0.86      0.84      2374\n",
    "           3       0.98      0.98      0.98     17587\n",
    "\n",
    "    accuracy                           0.96     41032\n",
    "   macro avg       0.92      0.93      0.93     41032\n",
    "weighted avg       0.97      0.96      0.96     41032\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 epochs with BART-large-CNN\n",
    "```\n",
    "Accuracy: 0.9893985182296744\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.98      0.97      3870\n",
    "           1       0.99      0.99      0.99     17201\n",
    "           2       0.97      0.95      0.96      2374\n",
    "           3       0.99      0.99      0.99     17587\n",
    "\n",
    "    accuracy                           0.99     41032\n",
    "   macro avg       0.98      0.98      0.98     41032\n",
    "weighted avg       0.99      0.99      0.99     41032\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and evaluating trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NLPClassifier(len(le.classes_), base_model).to(device)\n",
    "model.load_state_dict(torch.load(save_model_path(get_model_save_location(model_path))))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in tqdm(test_data_loader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    if multimodal:\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask, images) if multimodal else model(input_ids, attention_mask)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(le.inverse_transform(true_labels), le.inverse_transform(predictions)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a PyTorch dataset\n",
    "class ClassifierDataset(Dataset):\n",
    "    def __init__(self, texts, labels, images, tokenizer, processor, max_len):\n",
    "        self.texts = texts.to_numpy()\n",
    "        self.labels = labels\n",
    "        self.images = images.tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.processor = processor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(\n",
    "            './images/' + str(self.images[idx]) + '.jpg').convert('RGB')\n",
    "        # image = self.transform(image)\n",
    "        image = self.processor(image, return_tensors='pt').pixel_values.squeeze(0)\n",
    "\n",
    "        # print(\"SHAPE of image: \" + str(image.shape))\n",
    "\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'text': text,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'image': image,\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Create data loaders\n",
    "def create_data_loader(texts, labels, tokenizer, images, processor, max_len, batch_size):\n",
    "    ds = ClassifierDataset(\n",
    "        texts=texts,\n",
    "        labels=labels,\n",
    "        tokenizer=tokenizer,\n",
    "        images=images,\n",
    "        processor=processor,\n",
    "        max_len=max_len\n",
    "    )\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=4)\n",
    "\n",
    "\n",
    "class MMClassifier(nn.Module):\n",
    "    # TODO: add hidden layer size as parameter\n",
    "    def __init__(self, n_classes, nlp_model, image_model, fusion_mode, image_3d_vs_4d = True, hidden_layer_size=384):\n",
    "        super(MMClassifier, self).__init__()\n",
    "        self.fusion_mode = fusion_mode\n",
    "        self.image_3d_vs_4d = image_3d_vs_4d\n",
    "\n",
    "        self.nlp_model = nlp_model\n",
    "        self.image_model = image_model\n",
    "\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.hidden_size = self.get_hidden_size()\n",
    "\n",
    "        self.image_pooling = nn.AdaptiveAvgPool1d(1) if image_3d_vs_4d else nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.text_pooling = nn.AdaptiveAvgPool1d(1)\n",
    "\n",
    "        self.image_linear = nn.Linear(self.image_model.config.hidden_size, out_features=self.hidden_layer_size)\n",
    "        self.nlp_linear = nn.Linear(self.nlp_model.config.hidden_size, out_features=self.hidden_layer_size)\n",
    "        \n",
    "        self.hidden = nn.Linear(self.hidden_size, 128)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.out = nn.Linear(128, n_classes)\n",
    "\n",
    "    # Wrapper for the match statement for hidden size\n",
    "    def get_hidden_size(self):\n",
    "        match self.fusion_mode:\n",
    "            case 'concat':\n",
    "                return self.hidden_layer_size * 2\n",
    "            case 'mul' | 'add' | 'einsum':\n",
    "                return self.hidden_layer_size\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid fusion mode\")\n",
    "\n",
    "    def get_fused_output(self, text_pooled_output, image_pooled_output):\n",
    "        match self.fusion_mode:\n",
    "            case 'concat':\n",
    "                return torch.cat((text_pooled_output, image_pooled_output), dim=1)\n",
    "            case 'mul':\n",
    "                return text_pooled_output.mul(image_pooled_output)\n",
    "            case 'add':\n",
    "                return (text_pooled_output + image_pooled_output)/2\n",
    "            # TODO: using einsum  (need to work out some bugs) \n",
    "            case 'einsum':\n",
    "                return torch.einsum('ij,ij->ij', text_pooled_output, image_pooled_output)\n",
    "            case _:\n",
    "                raise ValueError(\"Invalid fusion mode\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, image):\n",
    "        text_output = self.nlp_model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        text_pooled_output = self.text_pooling(text_output.last_hidden_state.transpose(1, 2)).view(-1, self.nlp_model.config.hidden_size)\n",
    "        \n",
    "        image_output = self.image_model(image)\n",
    "\n",
    "        if self.image_3d_vs_4d:\n",
    "            image_pooled_output = self.image_pooling(image_output.hidden_states[-1].transpose(1, 2)).view(-1, self.image_model.config.hidden_size)\n",
    "        else:\n",
    "            image_pooled_output = self.image_pooling(image_output.hidden_states[-1]).view(-1, self.image_model.config.hidden_size)\n",
    "        \n",
    "        text_output = nn.ReLU()(self.nlp_linear(text_pooled_output))\n",
    "        image_output = nn.ReLU()(self.image_linear(image_pooled_output))\n",
    "\n",
    "        combined = self.get_fused_output(text_output, image_output)\n",
    "\n",
    "        # print(\"SHAPE of combined: \" + str(combined.shape))\n",
    "\n",
    "        output = self.drop(combined)\n",
    "        output = nn.ReLU()(self.hidden(output))\n",
    "        # return self.out(output)\n",
    "        return torch.nn.functional.log_softmax(self.out(output), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_output_tensor_shape(model_name: str):\n",
    "    tensor_3D = ['google/vit-base-patch16-224']\n",
    "    return model_name in tensor_3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal = True\n",
    "\n",
    "# Check if CUDA is available and set PyTorch to use GPU or CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "nlp_model_path = 'facebook/bart-large-cnn' # 'BAAI/bge-reranker-large' # 'facebook/bart-large-cnn' # 'roberta-base'\n",
    "image_model_path = 'google/vit-base-patch16-224' # 'microsoft/resnet-50' # 'google/vit-base-patch16-224'\n",
    "fusion_mode = 'concat'\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(nlp_model_path)\n",
    "nlp_model = AutoModel.from_pretrained(nlp_model_path).to(device)\n",
    "image_model = AutoModel.from_pretrained(image_model_path).to(device)\n",
    "processor = AutoImageProcessor.from_pretrained(image_model_path)\n",
    "image_model.config.output_hidden_states = True\n",
    "# Check if model.config.hidden_size exists, else assign to it model.config.hidden_sizes[-1]\n",
    "try:\n",
    "    image_model.config.hidden_size\n",
    "except:\n",
    "    image_model.config.hidden_size = image_model.config.hidden_sizes[-1]\n",
    "\n",
    "data_subset = df_combined#[:10]\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "encoded_labels = le.fit_transform(data_subset['classification_by_editorial'])\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_texts, test_texts, train_images, test_images, train_labels, test_labels = train_test_split(\n",
    "    data_subset['title'], data_subset[\"id\"], encoded_labels, test_size=0.2, random_state=42) # changed 'text' to 'title\n",
    "\n",
    "BATCH_SIZE = 100  # 50 consumes 22GB of VRAM\n",
    "MAX_LEN = 256\n",
    "\n",
    "train_data_loader = create_data_loader(train_texts, train_labels, tokenizer, train_images, processor, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_texts, test_labels, tokenizer, test_images, processor, MAX_LEN, BATCH_SIZE)\n",
    "\n",
    "# Initialize the classifier and optimizer\n",
    "model = MMClassifier(len(le.classes_), nlp_model, image_model, fusion_mode, model_output_tensor_shape(image_model_path)).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "loss_fn = CrossEntropyLoss().to(device)\n",
    "\n",
    "# Define the number of training epochs\n",
    "EPOCHS = 5\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'STARTING Epoch {epoch + 1}/{EPOCHS}')\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_data_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(test_data_loader):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        images = batch[\"image\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_test_loss = total_loss / len(test_data_loader)\n",
    "    test_losses.append(avg_test_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {avg_train_loss}, Test Loss: {avg_test_loss}\")\n",
    "\n",
    "# Plotting the training and testing losses\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Testing loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in tqdm(test_data_loader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    images = batch[\"image\"].to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "# Save model:\n",
    "torch.save(model.state_dict(), save_model_path(get_multimodal_model_save_location(nlp_model_path, image_model_path, fusion_mode)))\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(le.inverse_transform(true_labels), le.inverse_transform(predictions)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MMClassifier(len(le.classes_), nlp_model, image_model, fusion_mode, model_output_tensor_shape(image_model_path)).to(device)\n",
    "model.load_state_dict(torch.load(save_model_path(get_multimodal_model_save_location(nlp_model_path, image_model_path, fusion_mode))))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in tqdm(test_data_loader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    images = batch[\"image\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(le.inverse_transform(true_labels), le.inverse_transform(predictions)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ViT + Bart-Large-CNN concat titles only:\n",
    "```\n",
    "Accuracy: 0.9498671736004485\n",
    "Classification Report:\n",
    "                       precision    recall  f1-score   support\n",
    "\n",
    "      left_wing_in_US       0.90      0.91      0.91      3958\n",
    " left_wing_outside_US       0.96      0.96      0.96     17133\n",
    "     right_wing_in_US       0.88      0.84      0.86      2441\n",
    "right_wing_outside_US       0.96      0.96      0.96     17499\n",
    "\n",
    "             accuracy                           0.95     41031\n",
    "            macro avg       0.93      0.92      0.92     41031\n",
    "         weighted avg       0.95      0.95      0.95     41031\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained multimodal models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole dataset performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multimodal:\n",
    "    model = MMClassifier(len(le.classes_), nlp_model, image_model, fusion_mode, model_output_tensor_shape(image_model_path)).to(device)\n",
    "    model.load_state_dict(torch.load(save_model_path(get_multimodal_model_save_location(nlp_model_path, image_model_path, fusion_mode))))\n",
    "    whole_dataset_loader = create_data_loader(\n",
    "        data_subset['text'], encoded_labels, tokenizer, data_subset[\"id\"], processor, MAX_LEN, BATCH_SIZE)\n",
    "else:    \n",
    "    model = NLPClassifier(len(le.classes_), base_model).to(device)\n",
    "    model.load_state_dict(torch.load(\n",
    "        save_model_path(get_model_save_location(model_path))))\n",
    "    whole_dataset_loader = create_data_loader(\n",
    "        data_subset['text'], encoded_labels, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in tqdm(whole_dataset_loader):\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    images = batch[\"image\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask, images)\n",
    "\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(le.inverse_transform(\n",
    "    true_labels), le.inverse_transform(predictions)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whole dataset performance for Roberta + ViT (concat):\n",
    "```\n",
    "Accuracy: 0.9932051044581144\n",
    "Classification Report:\n",
    "                       precision    recall  f1-score   support\n",
    "\n",
    "      left_wing_in_US       0.97      0.99      0.98     19449\n",
    " left_wing_outside_US       1.00      1.00      1.00     85929\n",
    "     right_wing_in_US       0.99      0.96      0.97     12161\n",
    "right_wing_outside_US       1.00      1.00      1.00     87615\n",
    "\n",
    "             accuracy                           0.99    205154\n",
    "            macro avg       0.99      0.98      0.99    205154\n",
    "         weighted avg       0.99      0.99      0.99    205154\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_predictions = data_subset.copy()\n",
    "df_with_predictions['predicted_classification'] = le.inverse_transform(predictions)\n",
    "\n",
    "df_with_disagreeement = df_with_predictions[df_with_predictions['classification_by_editorial'] != df_with_predictions['predicted_classification']]\n",
    "df_with_disagreeement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if multimodal:\n",
    "    path_in_predictions = get_multimodal_model_save_location(nlp_model_path, image_model_path, fusion_mode)\n",
    "else:\n",
    "    path_in_predictions = get_model_save_location(model_path)\n",
    "    \n",
    "isExist = os.path.exists('./predictions/')\n",
    "if not isExist:\n",
    "   os.makedirs('./predictions/')\n",
    "\n",
    "df_with_disagreeement.to_csv('./predictions/' + path_in_predictions + '.csv')\n",
    "# for each of the disagreements save each row as formatted json in a file in the folder predictions\n",
    "isExist = os.path.exists('./predictions/' + path_in_predictions)\n",
    "if not isExist:\n",
    "   os.makedirs('./predictions/' + path_in_predictions)\n",
    "\n",
    "for index, row in df_with_disagreeement.iterrows():\n",
    "    with open('./predictions/' + path_in_predictions + '/' + str(row['id']) + '.json', 'w') as f:\n",
    "        f.write(row.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
